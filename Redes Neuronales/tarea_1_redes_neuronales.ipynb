{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12   \n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92  \\\n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos el dataset\n",
    "dataset = pd.read_csv('wine.data', header=None,skiprows=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 115, 63)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Ahora vamos a separar los datos de entrenamiento y los datos de prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.iloc[:, 1:], dataset.iloc[:, 0], test_size=0.35)\n",
    "\n",
    "len(dataset),len(X_train),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos nuestros conjuntos de datos\n",
    "# X_train_mean = X_train.mean()   \n",
    "# X_train_std = X_train.std()\n",
    "# X_train = (X_train - X_train_mean) / X_train_std\n",
    "\n",
    "# X_test_mean = X_test.mean()\n",
    "# X_test_std = X_test.std()\n",
    "# X_test = (X_test - X_test_mean) / X_test_std\n",
    "\n",
    "X_train = X_train/X_train.max()\n",
    "X_test = X_test/X_test.max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54     1\n",
       "174    3\n",
       "38     1\n",
       "51     1\n",
       "16     1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.287931</td>\n",
       "      <td>0.696594</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.848921</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.570866</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.452514</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.630952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.903574</td>\n",
       "      <td>0.674138</td>\n",
       "      <td>0.767802</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.733813</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.147638</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.393855</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.409357</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.446429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.881322</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0.650155</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.705036</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.519685</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.382682</td>\n",
       "      <td>0.284615</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.932569</td>\n",
       "      <td>0.284483</td>\n",
       "      <td>0.804954</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.676259</td>\n",
       "      <td>0.631443</td>\n",
       "      <td>0.588583</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.639665</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.8425</td>\n",
       "      <td>0.752976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.964262</td>\n",
       "      <td>0.331034</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.863309</td>\n",
       "      <td>0.721649</td>\n",
       "      <td>0.618110</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.550279</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.625731</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1         2         3         4         5         6         7    \n",
       "54   0.926500  0.287931  0.696594  0.546667  0.848921  0.670103  0.570866  \\\n",
       "174  0.903574  0.674138  0.767802  0.766667  0.733813  0.463918  0.147638   \n",
       "38   0.881322  0.258621  0.650155  0.516667  0.705036  0.618557  0.519685   \n",
       "51   0.932569  0.284483  0.804954  0.573333  0.676259  0.631443  0.588583   \n",
       "16   0.964262  0.331034  0.842105  0.666667  0.863309  0.721649  0.618110   \n",
       "\n",
       "           8         9         10        11      12        13  \n",
       "54   0.333333  0.452514  0.450000  0.538012  0.8000  0.630952  \n",
       "174  0.682540  0.393855  0.561538  0.409357  0.3900  0.446429  \n",
       "38   0.444444  0.382682  0.284615  0.690058  0.6725  0.607143  \n",
       "51   0.349206  0.639665  0.430769  0.725146  0.8425  0.752976  \n",
       "16   0.523810  0.550279  0.476923  0.625731  0.6625  0.761905  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Input, Dense, Activation, Flatten\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.1, 0.4]))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "HP_LEARNINGRATE= hp.HParam('learning_rate', hp.Discrete([0.1,0.01,0.001]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER, HP_LEARNINGRATE],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )\n",
    "\n",
    "def architecture(input_shape, num_classes, p_drop, units, dropout=True):\n",
    "    \n",
    "    # Defining the input as a tensor with shape input_shape. \n",
    "    InputLayer = Input(input_shape)\n",
    "    \n",
    "    # Defining the first hidden layer with 50 nodes and sigmoid as activation function\n",
    "    x = Dense(64, kernel_initializer='random_uniform', bias_initializer='zeros', name='hl_1')(InputLayer)\n",
    "    x = Activation('relu')(x)\n",
    "    if dropout == True:\n",
    "        x = Dropout(p_drop)(x)\n",
    "\n",
    "    x = Dense(128, kernel_initializer='random_uniform', bias_initializer='zeros', name='hl_2')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    if dropout == True:\n",
    "        x = Dropout(p_drop)(x)\n",
    "    \n",
    "    \n",
    "    # For the output layer we use the activation function 'softmax')\n",
    "    x = Dense(1, kernel_initializer='random_uniform', bias_initializer='zeros')(x)\n",
    "    OutputLayer = Activation('softmax', name='output-layer')(x)\n",
    "    \n",
    "    # This creates the Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = InputLayer, outputs = OutputLayer, name='Cifar10Model')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam', 'learning_rate': 0.001}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam', 'learning_rate': 0.01}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam', 'learning_rate': 0.1}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd', 'learning_rate': 0.001}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd', 'learning_rate': 0.01}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd', 'learning_rate': 0.1}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 16, 'dropout': 0.4, 'optimizer': 'adam', 'learning_rate': 0.001}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 16, 'dropout': 0.4, 'optimizer': 'adam', 'learning_rate': 0.01}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-8\n",
      "{'num_units': 16, 'dropout': 0.4, 'optimizer': 'adam', 'learning_rate': 0.1}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-9\n",
      "{'num_units': 16, 'dropout': 0.4, 'optimizer': 'sgd', 'learning_rate': 0.001}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-10\n",
      "{'num_units': 16, 'dropout': 0.4, 'optimizer': 'sgd', 'learning_rate': 0.01}\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-11\n",
      "{'num_units': 16, 'dropout': 0.4, 'optimizer': 'sgd', 'learning_rate': 0.1}\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-12\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adam', 'learning_rate': 0.001}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-13\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adam', 'learning_rate': 0.01}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-14\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adam', 'learning_rate': 0.1}\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-15\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'sgd', 'learning_rate': 0.001}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-16\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'sgd', 'learning_rate': 0.01}\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-17\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'sgd', 'learning_rate': 0.1}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-18\n",
      "{'num_units': 32, 'dropout': 0.4, 'optimizer': 'adam', 'learning_rate': 0.001}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-19\n",
      "{'num_units': 32, 'dropout': 0.4, 'optimizer': 'adam', 'learning_rate': 0.01}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-20\n",
      "{'num_units': 32, 'dropout': 0.4, 'optimizer': 'adam', 'learning_rate': 0.1}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-21\n",
      "{'num_units': 32, 'dropout': 0.4, 'optimizer': 'sgd', 'learning_rate': 0.001}\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-22\n",
      "{'num_units': 32, 'dropout': 0.4, 'optimizer': 'sgd', 'learning_rate': 0.01}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n",
      "--- Starting trial: run-23\n",
      "{'num_units': 32, 'dropout': 0.4, 'optimizer': 'sgd', 'learning_rate': 0.1}\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3175\n"
     ]
    }
   ],
   "source": [
    "num_classes=3\n",
    "\n",
    "def train_test_model(hparams):\n",
    "\n",
    "    model = architecture(input_shape=(13,), num_classes=num_classes, \n",
    "                       p_drop=hparams[HP_DROPOUT], units=hparams[HP_NUM_UNITS])\n",
    "    model.compile(\n",
    "          optimizer=hparams[HP_OPTIMIZER],\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy']\n",
    "      )\n",
    "    model.optimizer.learning_rate=hparams[HP_LEARNINGRATE]\n",
    "    model.fit(X_train, y_train, epochs = 1, batch_size = 32, \\\n",
    "                                validation_split = 0.01, shuffle=True, verbose=0) # Run with 1 epoch to speed things up for demo purposes\n",
    "    evaluations = model.evaluate(x = X_test, y = y_test)\n",
    "    accuracy = evaluations[1]\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def training(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "\n",
    "from collections import OrderedDict, namedtuple\n",
    "from itertools import product\n",
    "session_num = 0\n",
    "\n",
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        Run=namedtuple('Run', params.keys())\n",
    "\n",
    "        runs=[]\n",
    "\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs\n",
    "    \n",
    "params=OrderedDict(\n",
    "        num_units=[num_units for num_units in HP_NUM_UNITS.domain.values],\n",
    "        p_drop=[dropout_rate for dropout_rate in (HP_DROPOUT.domain.values)],\n",
    "        optim=[optimizer for optimizer in HP_OPTIMIZER.domain.values],\n",
    "        lr=[lr for lr in HP_LEARNINGRATE.domain.values],\n",
    "    )\n",
    "\n",
    "for run in RunBuilder().get_runs(params):\n",
    "    hparams = {\n",
    "          HP_NUM_UNITS: run.num_units,\n",
    "          HP_DROPOUT: run.p_drop,\n",
    "          HP_OPTIMIZER: run.optim,\n",
    "          HP_LEARNINGRATE: run.lr\n",
    "      }\n",
    "    run_name = \"run-%d\" % session_num\n",
    "    print('--- Starting trial: %s' % run_name)\n",
    "    print({h.name: hparams[h] for h in hparams})\n",
    "    training('logs/hparam_tuning/' + run_name, hparams)\n",
    "    session_num += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 115)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.3363 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(3, input_shape=(13,), activation=\"relu\"),\n",
    "    Dense(16, activation=\"tanh\"),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(1, activation=\"softmax\")\n",
    "])\n",
    "model.build(input_shape=(None, 13))\n",
    "\n",
    "# Probaremos varios optimizadores\n",
    "# model.compile(optimizer=(\"sgd\", \"rmsprop\", \"adagrad\", \"adadelta\", \"adam\", \"adamax\", \"nadam\"),\n",
    "# from tensorflow.python.keras.optimizers import adam\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history_small_model=model.fit(X_train, y_train, epochs=100, batch_size=8, validation_split=0.01, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABaq0lEQVR4nO3deVhUZf8G8HsGZNhkUZBFERQXRFEMxC1Dk8JEE5dEQlnEJbdU6s2MErU3sdcy19yF1Mwll3w1xQ3LFHcxTSIX3Fk0FUQJhHl+f/DjvI6ADggMHO/Pdc2lc85znud7nhmYm3POzCiEEAJEREREMqHUdQFEREREFYnhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGtJKdnY1hw4bB1tYWCoUCEyZMAACkp6djwIABqFu3LhQKBebMmaPTOsuitH0qiZOTE0JDQ6ustmfZtWsX3N3dYWhoCIVCgfv37wMAVq9eDRcXF9SqVQsWFhYAgK5du6Jr165lHkOhUGDq1KkVVrMchIaGwsnJqVzblvdxqImq088Kvbz0dV0A6U5sbCzCwsJKXZ+QkIAOHToAAGbMmIHY2Fh89tlncHZ2RosWLQAAEydORFxcHKKiomBrawtPT88Kr3PGjBlwdXWFv79/hfdb0j5VZ3///TcGDhyIli1bYuHChVCpVDAxMcGff/6J0NBQ9OjRAx9//DGMjY11XepzrV27FhkZGc8MlVTznT9/Hhs2bHihcKhLXbt2xZ07d3Du3Dldl0JlwHBDmD59Oho1alRseZMmTaT/79+/Hx06dEBUVJRGm/3796NPnz748MMPK62+GTNmYMCAARUebkrbp5IkJydDqdT9gc7jx4/jwYMH+Pzzz+Hj4yMtP3DgANRqNebOnavxuO3evbtc4+Tk5EBfv3J/Paxduxbnzp1juJGZp39Wzp8/j2nTpqFr1641MtxQzcRwQ3jrrbeee8QlIyMDrq6uJS4vOgVS05S2TyVRqVSVXI12MjIyAKDYnJe23MDAoFzjGBoalms7ourys0IvOUEvrZiYGAFAHD9+vNQ28fHxAkCxW9G2T9+K3Lt3T4wfP140aNBAGBgYCGdnZzFz5kxRUFCg0X9BQYGYM2eOaNWqlVCpVMLKykr4+vpKNZU0RkhIyDP3Kz09XQwdOlTUq1dPqFQq0bp1axEbG/vcfUpJSSm1T0dHR41xi/b/t99+ExMnThRWVlbC2NhY+Pv7i4yMDI1tjx8/Lt58801Rt25dYWhoKJycnERYWFixeuLj4zW2S0lJkeZaCCG8vb1LnAtHR8diy6OioqRtvL29NfrNyckRUVFRomnTpkKlUglbW1vRt29fcfHiRanNk30UuXHjhggLCxP16tUTBgYGwtXVVaxYsUKjTdG+rF+/Xvz73/8W9evXFyqVSrz++uviwoULUruS9sXR0bHU+S+qacyYMWLDhg2iRYsWwtDQUHTo0EH8/vvvQgghFi9eLJydnYVKpRLe3t4lPp4bNmwQr7zyijA0NBR169YVQUFB4saNG8XabdmyRbRs2VKoVCrRsmVLsXnzZmmun1RQUCC++eYb4erqKlQqlahXr54YMWKEuHv3rka7kh6H0qxevVq0a9dOGBkZCQsLC9GlSxcRFxcnrd+6davo2bOnsLOzEwYGBqJx48Zi+vTpIj8/v9iYLVu2FCdOnBAdO3aUnnuLFi3SaJebmys+++wz8corrwgzMzNhbGwsXn31VbF///5itT3v51UIzZ+V0n5PxMfHi+DgYFG3bl2Rl5dXbJw33nhDNGvW7Llzpc3jGRISIkxMTMSNGzdEnz59hImJibCyshIffPBBsTkrSdE8Ps/ChQuFq6urMDAwEHZ2dmL06NHi3r17Gm3++usv0a9fP2FjYyNUKpWoX7++CAgIEPfv35fa7N69W3Tu3FmYm5sLExMT0axZMzF58uTnjk+aeOSGkJmZiTt37mgsUygUqFu3Llq0aIHVq1dj4sSJaNCgAT744AMAQNu2bbF69WoMGTIEb7zxBoKDg6VtHz16BG9vb9y8eRMjR45Ew4YNcfjwYUyePBmpqakaFx2Hh4cjNjYWb731FoYNG4b8/HwcPHgQR44cgaenJ1avXo1hw4bBy8sLI0aMAAA4OzuXui85OTno2rUrLl68iLFjx6JRo0bYuHEjQkNDcf/+fYwfP77UfbK2ti7z3I0bNw6WlpaIiorClStXMGfOHIwdOxbr168HUHhE5c0334S1tTU+/vhjWFhY4MqVK9i8eXOZx4qMjETz5s2xdOlS6VSis7Mz/P39sWrVKmzZsgWLFi2CqakpWrduXWIfBQUF6NWrF/bt24dBgwZh/PjxePDgAfbs2YNz586VOrfp6eno0KEDFAoFxo4dC2tra+zcuRPh4eHIysoqdmpp5syZUCqV+PDDD5GZmYn//Oc/CAoKwtGjR6V9yczMxI0bN/DNN98AAExNTZ87BwcPHsS2bdswZswYAEB0dDR69eqFjz76CN9++y1Gjx6Ne/fu4T//+Q+GDh2K/fv3S9sWXWPWrl07REdHIz09HXPnzsWhQ4dw+vRp6ajX7t270b9/f7i6uiI6Ohp///03wsLC0KBBg2L1jBw5Uur3/fffR0pKChYsWIDTp0/j0KFDqFWr1nP36UnTpk3D1KlT0alTJ0yfPh0GBgY4evQo9u/fjzfffFPaD1NTU0RERMDU1BT79+/HlClTkJWVhVmzZmn0d+/ePfTs2RMDBw5EYGAgNmzYgFGjRsHAwABDhw4FAGRlZWH58uUIDAzE8OHD8eDBA6xYsQK+vr44duwY3N3dpf6e9/P6tNdeew3vv/8+5s2bh08++US6rq1FixYYMmQIVq1ahbi4OPTq1UvaJi0tDfv373/u6WJtH0+g8Hnv6+uL9u3b46uvvsLevXvx9ddfw9nZGaNGjSrTY1SSqVOnYtq0afDx8cGoUaOQnJyMRYsW4fjx49LzIC8vD76+vsjNzcW4ceNga2uLmzdvYvv27bh//z7Mzc3xxx9/oFevXmjdujWmT58OlUqFixcv4tChQy9c40tH1+mKdKe0v6oACJVKpdHW0dFR+Pn5FesD///X9JM+//xzYWJiIv766y+N5R9//LHQ09MT165dE0IIsX//fgFAvP/++8X6VavV0v9NTEyee7SmyJw5cwQAsWbNGmlZXl6e6NixozA1NRVZWVnP3aeSlHbkxsfHR6PWiRMnCj09PekvsS1btmh9dOx5R26eHPfp/qKiogQAcfv2bY3lTx8xWLlypQAgZs+eXayOJ/cDTx25CQ8PF3Z2duLOnTsa2wwaNEiYm5uLR48eaexLixYtRG5urtRu7ty5AoA4e/astMzPz++5R2ueVPS8fPKIzJIlSwQAYWtrq/HYTp48WeNoXF5enqhXr55o1aqVyMnJkdpt375dABBTpkyRlrm7uws7O7tif03jqaNLBw8eFADE999/r1Hnrl27ii3X5sjNhQsXhFKpFH379i12hPPJx6Zorp80cuRIYWxsLP755x+NMQGIr7/+WlqWm5sr3N3dRb169aQjJvn5+RqPlRCFR15tbGzE0KFDpWXa/rw+/bOycePGEp/fBQUFokGDBiIgIEBj+ezZs4VCoRCXL18uNk6RsjyeISEhAoCYPn26Rh9t27YVHh4epY5R5HlHbjIyMoSBgYF48803NR63BQsWCABi5cqVQgghTp8+LQCIjRs3ltrXN998U+LPMZWd7q+QJJ1buHAh9uzZo3HbuXNnufvbuHEjunTpAktLS9y5c0e6+fj4oKCgAL/++isAYNOmTVAoFCX+haZQKMo19s8//wxbW1sEBgZKy2rVqoX3338f2dnZ+OWXX8q3U6UYMWKERq1dunRBQUEBrl69CuB/18Bs374djx8/rtCxy2PTpk2wsrLCuHHjiq0rbc6FENi0aRN69+4NIYTGY+rr64vMzEycOnVKY5uwsDCN6326dOkCALh8+fIL1d+9e3eNi1Lbt28PAOjfvz9q165dbHnReCdOnEBGRgZGjx6tcT2Rn58fXFxcsGPHDgBAamoqEhMTERISAnNzc6ndG2+8Uez6rI0bN8Lc3BxvvPGGxpx4eHjA1NQU8fHxZdq3rVu3Qq1WY8qUKcUuXn/ysTEyMpL+/+DBA9y5cwddunTBo0eP8Oeff2psp6+vj5EjR0r3DQwMMHLkSGRkZODkyZMAAD09PemxUqvVuHv3LvLz8+Hp6anxuFb0z6tSqURQUBC2bduGBw8eSMu///57dOrUqcQ3ORTR9vF80nvvvadxv0uXLi/8fASAvXv3Ii8vDxMmTNB43IYPHw4zMzOplqLnU1xcHB49elRiX0W/L3766Seo1eoXru1lxnBD8PLygo+Pj8atW7du5e7vwoUL2LVrF6ytrTVuRe/uKbr49dKlS7C3t0edOnUqZD8A4OrVq2jatGmxF4eiw+FFoaOiNGzYUOO+paUlgMLTAQDg7e2N/v37Y9q0abCyskKfPn0QExOD3NzcCq1DW5cuXULz5s3L9E6o27dv4/79+1i6dGmxx7ToowSKHtMiz5uX8nq636IXDAcHhxKXF41X9Lg3b968WJ8uLi7S+qJ/mzZtWqzd09teuHABmZmZqFevXrF5yc7OLjYnz3Pp0iUolcrnXuT+xx9/oG/fvjA3N4eZmRmsra0xePBgAIWnmJ9kb28PExMTjWXNmjUDAFy5ckVa9t1336F169YwNDRE3bp1YW1tjR07dmj0Vxk/r8HBwcjJycGWLVsAFL7T6uTJkxgyZMgzt9P28SxiaGhY7LSzpaXlCz8fn1WLgYEBGjduLK1v1KgRIiIisHz5clhZWcHX1xcLFy7UmOOAgAB07twZw4YNg42NDQYNGoQNGzYw6JQDr7mhCqdWq/HGG2/go48+KnF90S9XOdDT0ytxuRACQOFftD/++COOHDmC//73v4iLi8PQoUPx9ddf48iRIzA1NS31r96CgoJKq7ssin6xDh48GCEhISW2efoan+fNS3mV1m9ljfcsarUa9erVw/fff1/i+vJcw/U89+/fh7e3N8zMzDB9+nQ4OzvD0NAQp06dwqRJk8r1IrhmzRqEhobC398f//rXv1CvXj3o6ekhOjoaly5dqvB9eJKrqys8PDywZs0aBAcHY82aNTAwMMDAgQMrdJzSnh9V7euvv0ZoaCh++ukn7N69G++//z6io6Nx5MgRNGjQAEZGRvj1118RHx+PHTt2YNeuXVi/fj1ef/117N69u9rsR03AcEMVztnZGdnZ2Rqfw1Jau7i4ONy9e/eZfw2W5ZC3o6Mjfv/9d6jVao2jN0WH6x0dHbXuqyJ16NABHTp0wBdffIG1a9ciKCgI69atw7Bhw6SjGkWfNFykoo8yAYVzfvToUTx+/Fjri12tra1Ru3ZtFBQUPPcxLYvynnosj6LHPTk5Ga+//rrGuuTkZGl90b8XLlwo1kdycrLGfWdnZ+zduxedO3fWOFVUXs7OzlCr1Th//rzGRbxPOnDgAP7++29s3rwZr732mrQ8JSWlxPa3bt3Cw4cPNY7e/PXXXwAgnd778ccf0bhxY2zevFnjMXn69JO2P69Pe97jHBwcjIiICKSmpmLt2rXw8/OTfiZKo+3jWRWerKVx48bS8ry8PKSkpBT7mXFzc4Obmxs+/fRTHD58GJ07d8bixYvx73//G0Dh6bru3buje/fumD17NmbMmIHIyEjEx8dX6M+f3PG0FFW4gQMHIiEhAXFxccXW3b9/H/n5+QAKr5MQQmDatGnF2j35F7eJiUmxF/7S9OzZE2lpadK7lQAgPz8f8+fPh6mpKby9vcu4Ny/m3r17xY4eFL1wFZ2acnR0hJ6ennQtUpFvv/22wuvp378/7ty5gwULFhRbV9pRDj09PfTv3x+bNm0q8VNab9++Xa5aTExMip1GqSyenp6oV68eFi9erHFKcOfOnUhKSoKfnx8AwM7ODu7u7vjuu+80atuzZw/Onz+v0efAgQNRUFCAzz//vNh4+fn5Wj9ni/j7+0OpVGL69OnFjsAUPTZFf7k/+Vjl5eWV+lzJz8/HkiVLNNouWbIE1tbW8PDwKLXPo0ePIiEhQaMvbX9en1YUrEqbj8DAQCgUCowfPx6XL1+WTrE9i7aPZ1Xw8fGBgYEB5s2bpzEPK1asQGZmplRLVlaW9LuviJubG5RKpbQPd+/eLdb/078vSDs8ckPYuXNnsQsRAaBTp04af4lo61//+he2bduGXr16ITQ0FB4eHnj48CHOnj2LH3/8EVeuXIGVlRW6deuGIUOGYN68ebhw4QJ69OgBtVqNgwcPolu3bhg7diwAwMPDA3v37sXs2bNhb2+PRo0aSReMPm3EiBFYsmQJQkNDcfLkSTg5OeHHH3/EoUOHMGfOHI2LTqvCd999h2+//RZ9+/aFs7MzHjx4gGXLlsHMzAw9e/YEUHh9yDvvvIP58+dDoVDA2dkZ27dvL/M1G9oIDg7GqlWrEBERgWPHjqFLly54+PAh9u7di9GjR6NPnz4lbjdz5kzEx8ejffv2GD58OFxdXXH37l2cOnUKe/fuLfGX8vN4eHhg/fr1iIiIQLt27WBqaorevXu/6C6WqFatWvjyyy8RFhYGb29vBAYGSm8ddnJywsSJE6W20dHR8PPzw6uvvoqhQ4fi7t27mD9/Plq2bIns7Gypnbe3N0aOHIno6GgkJibizTffRK1atXDhwgVs3LgRc+fOxYABA7SusUmTJoiMjMTnn3+OLl26oF+/flCpVDh+/Djs7e0RHR2NTp06wdLSEiEhIXj//fehUCiwevXqUsOFvb09vvzyS1y5cgXNmjXD+vXrkZiYiKVLl0pH7nr16oXNmzejb9++8PPzQ0pKChYvXgxXV1eN/dX25/Vp7u7u0NPTw5dffonMzEyoVCq8/vrrqFevHoDCI4M9evTAxo0bYWFhoVUwKcvjWRFu374tHVl5UqNGjRAUFITJkydj2rRp6NGjB95++20kJyfj22+/Rbt27aSwtn//fowdOxbvvPMOmjVrhvz8fKxevVr64wEo/LT4X3/9FX5+fnB0dERGRga+/fZbNGjQAK+++mqF7pPsVf0btKi6eNZbwfHUW5DL8lZwIYR48OCBmDx5smjSpIkwMDAQVlZWolOnTuKrr77S+NCu/Px8MWvWLOHi4iIMDAyEtbW1eOutt8TJkyelNn/++ad47bXXhJGRkdYf4hcWFiasrKyEgYGBcHNz09iX5+1TSUp7K/jTb8l++m3dp06dEoGBgaJhw4bSh7z16tVLnDhxQmO727dvi/79+wtjY2NhaWkpRo4cKc6dO1fhbwUXovCtxJGRkaJRo0aiVq1awtbWVgwYMEBcunRJaoMSPsQvPT1djBkzRjg4OEjbde/eXSxdurTY/j/9dteS3taenZ0t3n33XWFhYVGmD/Erqd9Zs2ZpLC+tjvXr14u2bdsKlUol6tSpU+qH+G3atEm0aNFCqFQq4erqWuqH+AkhxNKlS4WHh4cwMjIStWvXFm5ubuKjjz4St27dktqU5UP8Vq5cKdVoaWkpvL29xZ49e6T1hw4dEh06dBBGRkbC3t5efPTRRyIuLq7Y261L+hA/R0dHsWDBAo3x1Gq1mDFjhnB0dBQqlUq0bdtWbN++vcT91ebn9emfFSGEWLZsmWjcuLHQ09Mr8W3hGzZsEADEiBEjtJqjIto8nkUf4ve0op+Z5ynpAyeLbt27d5faLViwQLi4uIhatWoJGxsbMWrUKI0P8bt8+bIYOnSocHZ2FoaGhqJOnTqiW7duYu/evVKbffv2iT59+gh7e3thYGAg7O3tRWBgYLGP1aDnUwhRiVfcERGRTtSkL3z86aef4O/vj19//VX62ACiF8FrboiISKeWLVuGxo0b89QLVRhec0NERDqxbt06/P7779ixYwfmzp1bpe+gI3ljuCEiIp0IDAyEqakpwsPDMXr0aF2XQzLCa26IiIhIVnjNDREREckKww0RERHJykt3zY1arcatW7dQu3ZtXrxGRERUQwgh8ODBA9jb2xf7cuSnvXTh5tatW8W+QZiIiIhqhuvXr6NBgwbPbPPShZuij9+/fv06zMzMdFwNERERaSMrKwsODg5afY3OSxduik5FmZmZMdwQERHVMNpcUsILiomIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWqkW4WbhwIZycnGBoaIj27dvj2LFjpbaNjY2FQqHQuBkaGlZhtURERFSd6TzcrF+/HhEREYiKisKpU6fQpk0b+Pr6IiMjo9RtzMzMkJqaKt2uXr1ahRWX7sYNID6+8N+S7pe3TWX2zRqrVxtdj88aWWN1Gp81yqNGnRA65uXlJcaMGSPdLygoEPb29iI6OrrE9jExMcLc3Lzc42VmZgoAIjMzs9x9lGT5ciGUSiGAwn9DQjTvL19evjbl3a4q2+h6fNbIGqvT+KyRNVan8XVd4/LlFfc6W5bXb4UQQugqWOXl5cHY2Bg//vgj/P39peUhISG4f/8+fvrpp2LbxMbGYtiwYahfvz7UajVeeeUVzJgxAy1btixxjNzcXOTm5kr3i74yPTMzs8K+FfzGDcDREVCrS2+j/P9jZGVtU97tqrKNrsdnjayRNbJG1lg9a9TTA65cARo0KH07bWVlZcHc3Fyr12+dnpa6c+cOCgoKYGNjo7HcxsYGaWlpJW7TvHlzrFy5Ej/99BPWrFkDtVqNTp064UYpx7+io6Nhbm4u3RwcHCp8Py5cePYDDhSuL0+b8m5XlW10PT5rZI3VaXzWyBqr0/i6rrGgALh48dnbVQadX3NTVh07dkRwcDDc3d3h7e2NzZs3w9raGkuWLCmx/eTJk5GZmSndrl+/XuE1NW36v8RaGqWyfG3Ku11VttH1+KyRNVan8Vkja6xO4+u6Rj09oEmTZ29XGXQabqysrKCnp4f09HSN5enp6bC1tdWqj1q1aqFt27a4WEo0VKlUMDMz07hVtAYNgKVLCx9EoPDfkBDN+0uXlq9Neberyja6Hp81ssbqND5rZI3VaXxd17hkScWckiqzirvUp3y8vLzE2LFjpfsFBQWifv36pV5Q/LT8/HzRvHlzMXHiRK3aV9YFxUIIcf26EPHxhf+WdL+8bSqzb9ZYvdroenzWyBqr0/isUR41VpQac0ExUPhW8JCQECxZsgReXl6YM2cONmzYgD///BM2NjYIDg5G/fr1ER0dDQCYPn06OnTogCZNmuD+/fuYNWsWtm7dipMnT8LV1fW545XlgiQiIiKqHsry+q1fRTWVKiAgALdv38aUKVOQlpYGd3d37Nq1S7rI+Nq1a1A+cRLv3r17GD58ONLS0mBpaQkPDw8cPnxYq2BDRERE8qfzIzdVjUduiIiIap4a81ZwIiIioorGcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESyUi3CzcKFC+Hk5ARDQ0O0b98ex44d02q7devWQaFQwN/fv3ILJCIiohpD5+Fm/fr1iIiIQFRUFE6dOoU2bdrA19cXGRkZz9zuypUr+PDDD9GlS5cqqpSIiIhqAp2Hm9mzZ2P48OEICwuDq6srFi9eDGNjY6xcubLUbQoKChAUFIRp06ahcePGVVgtERERVXc6DTd5eXk4efIkfHx8pGVKpRI+Pj5ISEgodbvp06ejXr16CA8Pf+4Yubm5yMrK0rgRERGRfOk03Ny5cwcFBQWwsbHRWG5jY4O0tLQSt/ntt9+wYsUKLFu2TKsxoqOjYW5uLt0cHBxeuG4iIiKqvnR+WqosHjx4gCFDhmDZsmWwsrLSapvJkycjMzNTul2/fr2SqyQiIiJd0tfl4FZWVtDT00N6errG8vT0dNja2hZrf+nSJVy5cgW9e/eWlqnVagCAvr4+kpOT4ezsrLGNSqWCSqWqhOqJiIioOtLpkRsDAwN4eHhg37590jK1Wo19+/ahY8eOxdq7uLjg7NmzSExMlG5vv/02unXrhsTERJ5yIiIiIt0euQGAiIgIhISEwNPTE15eXpgzZw4ePnyIsLAwAEBwcDDq16+P6OhoGBoaolWrVhrbW1hYAECx5URERPRy0nm4CQgIwO3btzFlyhSkpaXB3d0du3btki4yvnbtGpTKGnVpEBEREemQQgghdF1EVcrKyoK5uTkyMzNhZmam63KIiIhIC2V5/eYhESIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVfV0XIBdCAI8e6boKIiKi6sHYGFAodDM2w00FefQIMDXVdRVERETVQ3Y2YGKim7F5WoqIiIhkhUduKoixcWFKJSIiosLXRV1huKkgCoXuDr8RERHR//C0FBEREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKv36BiKgGUavVyMvL03UZRJXCwMAASuWLH3dhuCEiqiHy8vKQkpICtVqt61KIKoVSqUSjRo1gYGDwQv0w3BAR1QBCCKSmpkJPTw8ODg4V8tctUXWiVqtx69YtpKamomHDhlAoFOXui+GGiKgGyM/Px6NHj2Bvbw9jY2Ndl0NUKaytrXHr1i3k5+ejVq1a5e6H0Z+IqAYoKCgAgBc+XE9UnRU9v4ue7+XFcENEVIO8yKF6ouquop7fDDdEREQkK9Ui3CxcuBBOTk4wNDRE+/btcezYsVLbbt68GZ6enrCwsICJiQnc3d2xevXqKqyWiIiIqjOdh5v169cjIiICUVFROHXqFNq0aQNfX19kZGSU2L5OnTqIjIxEQkICfv/9d4SFhSEsLAxxcXFVXDkRET1PaGgo/P39dV0GvWR0Hm5mz56N4cOHIywsDK6urli8eDGMjY2xcuXKEtt37doVffv2RYsWLeDs7Izx48ejdevW+O2336q4ciIiIqqOdBpu8vLycPLkSfj4+EjLlEolfHx8kJCQ8NzthRDYt28fkpOT8dprr5XYJjc3F1lZWRo3IqKX2o0bQHx84b869Msvv8DLywsqlQp2dnb4+OOPkZ+fL63/8ccf4ebmBiMjI9StWxc+Pj54+PAhAODAgQPw8vKCiYkJLCws0LlzZ1y9elVXu0LVjE7DzZ07d1BQUAAbGxuN5TY2NkhLSyt1u8zMTJiamsLAwAB+fn6YP38+3njjjRLbRkdHw9zcXLo5ODhU6D4QEdUoK1YAjo7A668X/rtihU7KuHnzJnr27Il27drhzJkzWLRoEVasWIF///vfAIDU1FQEBgZi6NChSEpKwoEDB9CvXz8IIZCfnw9/f394e3vj999/R0JCAkaMGMF3kpGkRn6IX+3atZGYmIjs7Gzs27cPERERaNy4Mbp27Vqs7eTJkxERESHdz8rKYsAhopfTjRvAiBFA0dc3qNXAyJGAry/QoEGVlvLtt9/CwcEBCxYsgEKhgIuLC27duoVJkyZhypQpSE1NRX5+Pvr16wdHR0cAgJubGwDg7t27yMzMRK9eveDs7AwAaNGiRZXWT9WbTsONlZUV9PT0kJ6errE8PT0dtra2pW6nVCrRpEkTAIC7uzuSkpIQHR1dYrhRqVRQqVQVWjcRUY104cL/gk2RggLg4sUqDzdJSUno2LGjxtGWzp07Izs7Gzdu3ECbNm3QvXt3uLm5wdfXF2+++SYGDBgAS0tL1KlTB6GhofD19cUbb7wBHx8fDBw4EHZ2dlW6D1R96fS0lIGBATw8PLBv3z5pmVqtxr59+9CxY0et+1Gr1cjNza2MEomI5KNpU+Dp76TS0wP+/4/F6kRPTw979uzBzp074erqivnz56N58+ZISUkBAMTExCAhIQGdOnXC+vXr0axZMxw5ckTHVVN1ofN3S0VERGDZsmX47rvvkJSUhFGjRuHhw4cICwsDAAQHB2Py5MlS++joaOzZsweXL19GUlISvv76a6xevRqDBw/W1S4QEdUMDRoAS5cWBhqg8N8lS6r8qA1QeBopISEBQghp2aFDh1C7dm00+P96FAoFOnfujGnTpuH06dMwMDDAli1bpPZt27bF5MmTcfjwYbRq1Qpr166t8v2g6knn19wEBATg9u3bmDJlCtLS0uDu7o5du3ZJFxlfu3ZN49tvHz58iNGjR+PGjRswMjKCi4sL1qxZg4CAAF3tAhFRzREeXniNzcWLhUdsqiDYZGZmIjExUWPZiBEjMGfOHIwbNw5jx45FcnIyoqKiEBERAaVSiaNHj2Lfvn148803Ua9ePRw9ehS3b99GixYtkJKSgqVLl+Ltt9+Gvb09kpOTceHCBQQHB1f6vlANIV4ymZmZAoDIzMzUdSlERFrLyckR58+fFzk5OboupUxCQkIEgGK38PBwceDAAdGuXTthYGAgbG1txaRJk8Tjx4+FEEKcP39e+Pr6Cmtra6FSqUSzZs3E/PnzhRBCpKWlCX9/f2FnZycMDAyEo6OjmDJliigoKNDlrlIFeNbzvCyv3wohnjgm+BLIysqCubk5MjMzYWZmputyiIi08s8//yAlJQWNGjWCoaGhrsshqhTPep6X5fVb59fcEBEREVUkhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIqp0CQkJ0NPTg5+fn65LoZcAww0REVW6FStWYNy4cfj1119x69YtndWRl5ens7Gp6jDcEBFRpcrOzsb69esxatQo+Pn5ITY2VmP9f//7X7Rr1w6GhoawsrJC3759pXW5ubmYNGkSHBwcoFKp0KRJE6xYsQIAEBsbCwsLC42+tm7dCoVCId2fOnUq3N3dsXz5co0vY9y1axdeffVVWFhYoG7duujVqxcuXbqk0deNGzcQGBiIOnXqwMTEBJ6enjh69CiuXLkCpVKJEydOaLSfM2cOHB0doVarX3TK6AXp67oAIiIqOyGAR490M7axMfBEfniuDRs2wMXFBc2bN8fgwYMxYcIETJ48GQqFAjt27EDfvn0RGRmJVatWIS8vDz///LO0bXBwMBISEjBv3jy0adMGKSkpuHPnTpnqvXjxIjZt2oTNmzdDT08PAPDw4UNERESgdevWyM7OxpQpU9C3b18kJiZCqVQiOzsb3t7eqF+/PrZt2wZbW1ucOnUKarUaTk5O8PHxQUxMDDw9PaVxYmJiEBoaCqWSxw10TpTDtWvXxPXr16X7R48eFePHjxdLliwpT3dVKjMzUwAQmZmZui6FiEhrOTk54vz58yInJ0cIIUR2thCFEafqb9nZZau9U6dOYs6cOUIIIR4/fiysrKxEfHy8EEKIjh07iqCgoBK3S05OFgDEnj17SlwfExMjzM3NNZZt2bJFPPnSFhUVJWrVqiUyMjKeWePt27cFAHH27FkhhBBLliwRtWvXFn///XeJ7devXy8sLS3FP//8I4QQ4uTJk0KhUIiUlJRnjkPP9vTz/Ellef0uV7x89913ER8fDwBIS0vDG2+8gWPHjiEyMhLTp0+vqNxFREQ1XHJyMo4dO4bAwEAAgL6+PgICAqRTS4mJiejevXuJ2yYmJkJPTw/e3t4vVIOjoyOsra01ll24cAGBgYFo3LgxzMzM4OTkBAC4du2aNHbbtm1Rp06dEvv09/eHnp4etmzZAqDwFFm3bt2kfki3ynVa6ty5c/Dy8gJQeLixVatWOHToEHbv3o333nsPU6ZMqdAiiYhIk7ExkJ2tu7G1tWLFCuTn58Pe3l5aJoSASqXCggULYGRkVOq2z1oHAEqlEkIIjWWPHz8u1s7ExKTYst69e8PR0RHLli2Dvb091Go1WrVqJV1w/LyxDQwMEBwcjJiYGPTr1w9r167F3Llzn7kNVZ1yhZvHjx9DpVIBAPbu3Yu3334bAODi4oLU1NSKq46IiEqkUAAlvGZXK/n5+Vi1ahW+/vprvPnmmxrr/P398cMPP6B169bYt28fwsLCim3v5uYGtVqNX375BT4+PsXWW1tb48GDB3j48KEUYBITE59b199//43k5GQsW7YMXbp0AQD89ttvGm1at26N5cuX4+7du6UevRk2bBhatWqFb7/9Fvn5+ejXr99zx6aqUa7TUi1btsTixYtx8OBB7NmzBz169AAA3Lp1C3Xr1q3QAomIqGbavn077t27h/DwcLRq1Urj1r9/f6xYsQJRUVH44YcfEBUVhaSkJJw9exZffvklAMDJyQkhISEYOnQotm7dipSUFBw4cAAbNmwAALRv3x7Gxsb45JNPcOnSJaxdu7bYO7FKYmlpibp162Lp0qW4ePEi9u/fj4iICI02gYGBsLW1hb+/Pw4dOoTLly9j06ZNSEhIkNq0aNECHTp0wKRJkxAYGPjcoz1UdcoVbr788kssWbIEXbt2RWBgINq0aQMA2LZtm3S6ioiIXm4rVqyAj48PzM3Ni63r378/Tpw4gTp16mDjxo3Ytm0b3N3d8frrr+PYsWNSu0WLFmHAgAEYPXo0XFxcMHz4cDx8+BAAUKdOHaxZswY///wz3Nzc8MMPP2Dq1KnPrUupVGLdunU4efIkWrVqhYkTJ2LWrFkabQwMDLB7927Uq1cPPXv2hJubG2bOnCm926pIeHg48vLyMHTo0HLMEFUWhXj6hKWWCgoKkJWVBUtLS2nZlStXYGxsjHr16lVYgRUtKysL5ubmyMzMhJmZma7LISLSyj///IOUlBSNz2oh3fv888+xceNG/P7777ouRRae9Twvy+t3uY7c5OTkIDc3Vwo2V69exZw5c5CcnFytgw0REVFFyM7Oxrlz57BgwQKMGzdO1+XQU8oVbvr06YNVq1YBAO7fv4/27dvj66+/hr+/PxYtWlShBRIREVU3Y8eOhYeHB7p27cpTUtVQucLNqVOnpCvMf/zxR9jY2ODq1atYtWoV5s2bV6EFEhERVTexsbHIzc3F+vXri12HQ7pXrnDz6NEj1K5dGwCwe/du9OvXD0qlEh06dMDVq1crtEAiIiKisihXuGnSpAm2bt2K69evIy4uTvr8goyMDF6kS0RERDpVrnAzZcoUfPjhh3BycoKXlxc6duwIoPAoTtu2bSu0QCIiIqKyKNcnFA8YMACvvvoqUlNTpc+4AYDu3btrfFU9ERERUVUrV7gBAFtbW9ja2uLGjRsAgAYNGvAD/IiIiEjnynVaSq1WY/r06TA3N4ejoyMcHR1hYWGBzz//HGq1uqJrJCIiItJaucJNZGQkFixYgJkzZ+L06dM4ffo0ZsyYgfnz5+Ozzz6r6BqJiOgl1rVrV0yYMEG67+TkhDlz5jxzG4VCga1bt77w2BXVD1WtcoWb7777DsuXL8eoUaPQunVrtG7dGqNHj8ayZcu0+tIyIiKSv969e0tfrPy0gwcPQqFQlOtrC44fP44RI0a8aHkapk6dCnd392LLU1NT8dZbb1XoWE+LjY2FhYVFpY7xsilXuLl79y5cXFyKLXdxccHdu3dfuCgiIqr5wsPDsWfPHunazCfFxMTA09MTrVu3LnO/1tbWMDY2rogSn8vW1hYqlapKxqKKU65w06ZNGyxYsKDY8gULFpTriUpERPLTq1cvWFtbFzuin52djY0bNyI8PBx///03AgMDUb9+fRgbG0vf7v0sT5+WunDhAl577TUYGhrC1dUVe/bsKbbNpEmT0KxZMxgbG6Nx48b47LPP8PjxYwCFR06mTZuGM2fOQKFQQKFQSDU/fVrq7NmzeP3112FkZIS6detixIgRyM7OltaHhobC398fX331Fezs7FC3bl2MGTNGGqs8rl27hj59+sDU1BRmZmYYOHAg0tPTpfVnzpxBt27dULt2bZiZmcHDwwMnTpwAUPjdj71794alpSVMTEzQsmVL/Pzzz+WupaYo17ul/vOf/8DPzw979+6VPuMmISEB169ffykmjYio2nj4sPR1enrAk9+s/Ky2SiVgZPT8tiYmWpemr6+P4OBgxMbGIjIyEgqFAgCwceNGFBQUIDAwENnZ2fDw8MCkSZNgZmaGHTt2YMiQIXB2dtbqHbhqtRr9+vWDjY0Njh49iszMTI3rc4rUrl0bsbGxsLe3x9mzZzF8+HDUrl0bH330EQICAnDu3Dns2rULe/fuBQCYm5sX6+Phw4fw9fVFx44dcfz4cWRkZGDYsGEYO3asRoCLj4+HnZ0d4uPjcfHiRQQEBMDd3R3Dhw/Xeu6e3L+iYPPLL78gPz8fY8aMQUBAAA4cOAAACAoKQtu2bbFo0SLo6ekhMTERtWrVAgCMGTMGeXl5+PXXX2FiYoLz58/D1NS0zHXUOKKcbt68KT755BPRr18/0a9fPxEZGSmuXr0qhg8fXt4uq0RmZqYAIDIzM3VdChGR1nJycsT58+dFTk6O5gqg9FvPnpptjY1Lb+vtrdnWyqrkdmWUlJQkAIj4+HhpWZcuXcTgwYNL3cbPz0988MEH0n1vb28xfvx46b6jo6P45ptvhBBCxMXFCX19fXHz5k1p/c6dOwUAsWXLllLHmDVrlvDw8JDuR0VFiTZt2hRr92Q/S5cuFZaWliI7O1tav2PHDqFUKkVaWpoQQoiQkBDh6Ogo8vPzpTbvvPOOCAgIKLWWmJgYYW5uXuK63bt3Cz09PXHt2jVp2R9//CEAiGPHjgkhhKhdu7aIjY0tcXs3NzcxderUUseubkp9nouyvX6X+3Nu7O3t8cUXX2gsO3PmDFasWIGlS5e+QNwiIiK5cHFxQadOnbBy5Up07doVFy9exMGDBzF9+nQAQEFBAWbMmIENGzbg5s2byMvLQ25urtbX1CQlJcHBwQH29vbSsqIzCk9av3495s2bh0uXLiE7Oxv5+fll/rqgpKQktGnTBiZPHL3q3Lkz1Go1kpOTYWNjAwBo2bKlxpdp2tnZ4ezZs2Ua68kxHRwc4ODgIC1zdXWFhYUFkpKS0K5dO0RERGDYsGFYvXo1fHx88M4778DZ2RkA8P7772PUqFHYvXs3fHx80L9//5fi8pFyXXNDRETVRHZ26bdNmzTbZmSU3nbnTs22V66U3K4cwsPDsWnTJjx48AAxMTFwdnaGt7c3AGDWrFmYO3cuJk2ahPj4eCQmJsLX1xd5eXnlGqskCQkJCAoKQs+ePbF9+3acPn0akZGRFTrGk4pOCRVRKBSV+hlwU6dOxR9//AE/Pz/s378frq6u2LJlCwBg2LBhuHz5MoYMGYKzZ8/C09MT8+fPr7RaqguGGyKimszEpPTbk9fbPK/tk9fbPKttOQwcOBBKpRJr167FqlWrMHToUOn6m0OHDqFPnz4YPHgw2rRpg8aNG+Ovv/7Suu8WLVrg+vXrSE1NlZYdOXJEo83hw4fh6OiIyMhIeHp6omnTprh69apGGwMDAxQUFDx3rDNnzuDhE9cjHTp0CEqlEs2bN9e65rIo2r/r169Ly86fP4/79+/D1dVVWtasWTNMnDgRu3fvRr9+/RATEyOtc3BwwHvvvYfNmzfjgw8+wLJlyyql1uqE4YaIiCqVqakpAgICMHnyZKSmpiI0NFRa17RpU+zZsweHDx9GUlISRo4cqfFOoOfx8fFBs2bNEBISgjNnzuDgwYOIjIzUaNO0aVNcu3YN69atw6VLlzBv3jzpyEYRJycnpKSkIDExEXfu3EFubm6xsYKCgmBoaIiQkBCcO3cO8fHxGDduHIYMGSKdkiqvgoICJCYmatySkpLg4+MDNzc3BAUF4dSpUzh27BiCg4Ph7e0NT09P5OTkYOzYsThw4ACuXr2KQ4cO4fjx42jRogUAYMKECYiLi0NKSgpOnTqF+Ph4aZ2clemam379+j1z/f3791+kFiIikqnw8HCsWLECPXv21Lg+5tNPP8Xly5fh6+sLY2NjjBgxAv7+/sjMzNSqX6VSiS1btiA8PBxeXl5wcnLCvHnzND488O2338bEiRMxduxY5Obmws/PD5999hmmTp0qtenfvz82b96Mbt264f79+4iJidEIYQBgbGyMuLg4jB8/Hu3atYOxsTH69++P2bNnv9DcAIVvj2/btq3GMmdnZ1y8eBE//fQTxo0bh9deew1KpRI9evSQTi3p6enh77//RnBwMNLT02FlZYV+/fph2rRpAApD05gxY3Djxg2YmZmhR48e+Oabb1643upOIYQQ2jYOCwvTqt2Th8Oqm6ysLJibmyMzM7PMF5MREenKP//8g5SUFDRq1AiGT59uIpKJZz3Py/L6XaYjN9U5tBAREREBvOaGiIiIZIbhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiKq1rl27YsKECdJ9JycnzJkz55nbKBQKbN269YXHrqh+qGox3BARUaXo3bu3xnc8PengwYNQKBT4/fffy9zv8ePHMWLEiBctT8PUqVPh7u5ebHlqaireeuutCh2rNDk5OahTpw6srKxK/OJO0h7DDRHRS+bGDSA+vvDfyhQeHo49e/bgRgkDxcTEwNPTE61bty5zv9bW1jA2Nq6IEp/L1tYWKpWqSsbatGkTWrZsCRcXF50fLRJCID8/X6c1vAiGGyKil8iKFYCjI/D664X/rlhReWP16tUL1tbWiI2N1VienZ2NjRs3Ijw8HH///TcCAwNRv359GBsbw83NDT/88MMz+336tNSFCxfw2muvwdDQEK6urtizZ0+xbSZNmoRmzZrB2NgYjRs3xmeffYbHjx8DAGJjYzFt2jScOXMGCoUCCoVCqvnp01Jnz57F66+/DiMjI9StWxcjRoxAdna2tD40NBT+/v746quvYGdnh7p162LMmDHSWM+yYsUKDB48GIMHD8aKEh6YP/74A7169YKZmRlq166NLl264NKlS9L6lStXomXLllCpVLCzs8PYsWMBAFeuXIFCoUBiYqLU9v79+1AoFDhw4AAA4MCBA1AoFNi5cyc8PDygUqnw22+/4dKlS+jTpw9sbGxgamqKdu3aYe/evRp15ebmYtKkSXBwcIBKpUKTJk2wYsUKCCHQpEkTfPXVVxrtExMToVAocPHixefOSXlVi3CzcOFCODk5wdDQEO3bt8exY8dKbbts2TJ06dIFlpaWsLS0hI+PzzPbExFRoRs3gBEjALW68L5aDYwcWXlHcPT19REcHIzY2FgIIaTlGzduREFBAQIDA/HPP//Aw8MDO3bswLlz5zBixAgMGTJE69/rarUa/fr1g4GBAY4ePYrFixdj0qRJxdrVrl0bsbGxOH/+PObOnYtly5bhm2++AQAEBATggw8+QMuWLZGamorU1FQEBAQU6+Phw4fw9fWFpaUljh8/jo0bN2Lv3r1SiCgSHx+PS5cuIT4+Ht999x1iY2OLBbynXbp0CQkJCRg4cCAGDhyIgwcP4urVq9L6mzdv4rXXXoNKpcL+/ftx8uRJDB06VDq6smjRIowZMwYjRozA2bNnsW3bNjRp0kSrOXzSxx9/jJkzZyIpKQmtW7dGdnY2evbsiX379uH06dPo0aMHevfujWvXrknbBAcH44cffsC8efOQlJSEJUuWwNTUFAqFAkOHDi32pdsxMTF47bXXylWf1oSOrVu3ThgYGIiVK1eKP/74QwwfPlxYWFiI9PT0Etu/++67YuHCheL06dMiKSlJhIaGCnNzc3Hjxg2txsvMzBQARGZmZkXuBhFRpcrJyRHnz58XOTk55e5j/34hgOK3+PiKq/NpSUlJAoCIf2KQLl26iMGDB5e6jZ+fn/jggw+k+97e3mL8+PHSfUdHR/HNN98IIYSIi4sT+vr64ubNm9L6nTt3CgBiy5YtpY4xa9Ys4eHhId2PiooSbdq0KdbuyX6WLl0qLC0tRXZ2trR+x44dQqlUirS0NCGEECEhIcLR0VHk5+dLbd555x0REBBQai1CCPHJJ58If39/6X6fPn1EVFSUdH/y5MmiUaNGIi8vr8Tt7e3tRWRkZInrUlJSBABx+vRpadm9e/c0Hpf4+HgBQGzduvWZdQohRMuWLcX8+fOFEEIkJycLAGLPnj0ltr1586bQ09MTR48eFUIIkZeXJ6ysrERsbGyJ7Z/1PC/L67fOj9zMnj0bw4cPR1hYGFxdXbF48WIYGxtj5cqVJbb//vvvMXr0aLi7u8PFxQXLly+HWq3Gvn37qrhyIqKapWlTQPnUb309PaAy/4B2cXFBp06dpN/pFy9exMGDBxEeHg4AKCgowOeffw43NzfUqVMHpqamiIuL0zgy8CxJSUlwcHCAvb29tKxjx47F2q1fvx6dO3eGra0tTE1N8emnn2o9xpNjtWnTBiYmJtKyzp07Q61WIzk5WVrWsmVL6OnpSfft7OyQkZFRar8FBQX47rvvMHjwYGnZ4MGDERsbC/X/H2ZLTExEly5dUKtWrWLbZ2Rk4NatW+jevXuZ9qcknp6eGvezs7Px4YcfokWLFrCwsICpqSmSkpKkuUtMTISenh68vb1L7M/e3h5+fn7S4//f//4Xubm5eOedd1641mfRabjJy8vDyZMn4ePjIy1TKpXw8fFBQkKCVn08evQIjx8/Rp06dSqrTCIiWWjQAFi6tDDQAIX/LllSuLwyhYeHY9OmTXjw4AFiYmLg7OwsvRjOmjULc+fOxaRJkxAfH4/ExET4+voiLy+vwsZPSEhAUFAQevbsie3bt+P06dOIjIys0DGe9HQAUSgUUkgpSVxcHG7evImAgADo6+tDX18fgwYNwtWrV6U/3I2MjErd/lnrgMLXVQAapwZLuwboyeAGAB9++CG2bNmCGTNm4ODBg0hMTISbm5s0d88bGwCGDRuGdevWIScnBzExMQgICKj0C8J1Gm7u3LmDgoIC2NjYaCy3sbFBWlqaVn1MmjQJ9vb2GgHpSbm5ucjKytK4ERG9rMLDgStXCt8tdeVK4f3KNnDgQCiVSqxduxarVq3C0KFDoVAoAACHDh1Cnz59MHjwYLRp0waNGzfGX3/9pXXfLVq0wPXr15GamiotO3LkiEabw4cPw9HREZGRkfD09ETTpk01rmcBAAMDAxQUFDx3rDNnzuDhw4fSskOHDkGpVKJ58+Za1/y0FStWYNCgQUhMTNS4DRo0SLqwuHXr1jh48GCJoaR27dpwcnIq9QyGtbU1AGjM0ZMXFz/LoUOHEBoair59+8LNzQ22tra4cuWKtN7NzQ1qtRq//PJLqX307NkTJiYmWLRoEXbt2oWhQ4dqNfaL0PlpqRcxc+ZMrFu3Dlu2bIGhoWGJbaKjo2Fubi7dHBwcqrhKIqLqpUEDoGvXyj9iU8TU1BQBAQGYPHkyUlNTERoaKq1r2rQp9uzZg8OHDyMpKQkjR45Eenq61n37+PigWbNmCAkJwZkzZ3Dw4EFERkZqtGnatCmuXbuGdevW4dKlS5g3bx62bNmi0cbJyQkpKSlITEzEnTt3SvycmaCgIBgaGiIkJATnzp1DfHw8xo0bhyFDhhT7I11bt2/fxn//+1+EhISgVatWGrfg4GBs3boVd+/exdixY5GVlYVBgwbhxIkTuHDhAlavXi2dDps6dSq+/vprzJs3DxcuXMCpU6cwf/58AIVHVzp06CBdKPzLL7/g008/1aq+pk2bYvPmzUhMTMSZM2fw7rvvahyFcnJyQkhICIYOHYqtW7ciJSUFBw4cwIYNG6Q2enp6CA0NxeTJk9G0adMSTxtWNJ2GGysrK+jp6RV7Iqenp8PW1vaZ23711VeYOXMmdu/e/czPSZg8eTIyMzOl2/Xr1yukdiIi0l54eDju3bsHX19fjetjPv30U7zyyivw9fVF165dYWtrC39/f637VSqV2LJlC3JycuDl5YVhw4bhiy++0Gjz9ttvY+LEiRg7dizc3d1x+PBhfPbZZxpt+vfvjx49eqBbt26wtrYu8e3oxsbGiIuLw927d9GuXTsMGDAA3bt3x4IFC8o2GU9YtWoVTExMSrxepnv37jAyMsKaNWtQt25d7N+/H9nZ2fD29oaHhweWLVsmnQILCQnBnDlz8O2336Jly5bo1asXLly4IPW1cuVK5Ofnw8PDAxMmTMC///1vreqbPXs2LC0t0alTJ/Tu3Ru+vr545ZVXNNosWrQIAwYMwOjRo+Hi4oLhw4drHN0CCh//vLw8hIWFlXWKykUhnjwJpwPt27eHl5eXlDDVajUaNmyIsWPH4uOPPy5xm//85z/44osvEBcXhw4dOpRpvKysLJibmyMzMxNmZmYvXD8RUVX4559/kJKSgkaNGpV6pJqoujp48CC6d++O69evP/Mo17Oe52V5/davkKpfQEREBEJCQuDp6QkvLy/MmTMHDx8+lNJdcHAw6tevj+joaADAl19+iSlTpmDt2rVwcnKSrs0xNTWFqampzvaDiIiINOXm5uL27duYOnUq3nnnnXKfvisrnYebgIAA3L59G1OmTEFaWhrc3d2xa9cuaQKuXbsmXekNFB7+ysvLw4ABAzT6iYqKwtSpU6uydCIiInqGH374AeHh4XB3d8eqVauqbFydn5aqajwtRUQ1EU9L0cugok5L1eh3SxERERE9jeGGiKgGeckOttNLpqKe3ww3REQ1QNHH+VfWp+oSVQdFz+8nv76iPHR+QTERET2fvr4+jI2Ncfv2bdSqVUvjjRZEcqBWq3H79m0YGxtDX//F4gnDDRFRDaBQKGBnZ4eUlJRiXx1AJBdKpRINGzaUvp6jvBhuiIhqCAMDAzRt2pSnpki2DAwMKuSoJMMNEVENolQq+VZwoufgSVsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFZ2Hm4ULF8LJyQmGhoZo3749jh07VmrbP/74A/3794eTkxMUCgXmzJlTdYUSERFRjaDTcLN+/XpEREQgKioKp06dQps2beDr64uMjIwS2z969AiNGzfGzJkzYWtrW8XVEhERUU2g03Aze/ZsDB8+HGFhYXB1dcXixYthbGyMlStXlti+Xbt2mDVrFgYNGgSVSlXF1RIREVFNoLNwk5eXh5MnT8LHx+d/xSiV8PHxQUJCgq7KIiIiohpOX1cD37lzBwUFBbCxsdFYbmNjgz///LPCxsnNzUVubq50Pysrq8L6JiIioupH5xcUV7bo6GiYm5tLNwcHB12XRERERJVIZ+HGysoKenp6SE9P11ienp5eoRcLT548GZmZmdLt+vXrFdY3ERERVT86CzcGBgbw8PDAvn37pGVqtRr79u1Dx44dK2wclUoFMzMzjRsRERHJl86uuQGAiIgIhISEwNPTE15eXpgzZw4ePnyIsLAwAEBwcDDq16+P6OhoAIUXIZ8/f176/82bN5GYmAhTU1M0adJEZ/tBRERE1YdOw01AQABu376NKVOmIC0tDe7u7ti1a5d0kfG1a9egVP7v4NKtW7fQtm1b6f5XX32Fr776Ct7e3jhw4EBVl09ERETVkEIIIXRdRFXKysqCubk5MjMzeYqKiIiohijL67fs3y1FRERELxeGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSlWoRbhYuXAgnJycYGhqiffv2OHbs2DPbb9y4ES4uLjA0NISbmxt+/vnnKqqUiIiIqjudh5v169cjIiICUVFROHXqFNq0aQNfX19kZGSU2P7w4cMIDAxEeHg4Tp8+DX9/f/j7++PcuXNVXHkJbtwA4uML/y3pfnnbVGbfrLF6tdH1+KyRNVan8VmjPGrUBaFjXl5eYsyYMdL9goICYW9vL6Kjo0tsP3DgQOHn56exrH379mLkyJFajZeZmSkAiMzMzPIXXZLly4VQKoUAhFAohHj33cJ/i+4vXCjEokX/a6NUltxm4cL/LVMqC/tdvlyz3dPbffutduM/3XdIyLPbKBSFbZ7st6Q2Rcue3LegIO3Gf17f776r2e+iRSW3efJ+SXNWUt/BwdqN//TjsXjxs8dfurR8j8fixeXbt5L6XrKkcp4PixeXb9+GDKmY59rTj8fSpaU/H8u6b4MHl+/5sGzZsx+PRYuKz5m2fWv7fHje4/Htt2X/+dT2uVbdfvcMHlw5zzX+7tHu+bB4sebjsXx5hb3MluX1WyGEELoKVnl5eTA2NsaPP/4If39/aXlISAju37+Pn376qdg2DRs2REREBCZMmCAti4qKwtatW3HmzJli7XNzc5Gbmyvdz8rKgoODAzIzM2FmZlYxO3LjBuDoCKjVFdPfk5T/f3DteX0rlZUzfk2k7ZyVt+/n9atQFN7KOr5CATzvx1HbfdOmr/Io775VlsraT20plYXja/O4lXXOtNmmsp/r2vTN3z3/U9mPx/Oea9Xxd4+eHnDlCtCgQdlqKkFWVhbMzc21ev3W6WmpO3fuoKCgADY2NhrLbWxskJaWVuI2aWlpZWofHR0Nc3Nz6ebg4FAxxT/pwoXK++FWq7Xrm79c/kfbOStv388jRPnG1+ZFWtt9q6wX/PLuW2XRZbABCudC28etPH1r04a/e6qPyn48nvdcq46/ewoKgIsXy17TC9L5NTeVbfLkycjMzJRu169fr/hBmjb9X6otTVGiLmsbpVK7vitrfG3aVGbf5WlT0pxVZN/a9FOex6O8+6ZN3xXVRtfPNW1rrMrnWnmeDxXVd2U+H/i7p+xt+LuneD96ekCTJs/erhLoNNxYWVlBT08P6enpGsvT09Nha2tb4ja2trZlaq9SqWBmZqZxq3ANGgBLlxY+iEDhvyEhmveXLSu8lbXN0qXa9V1Z42vTpjL7Lk+bkuasIvvWpp/yPB7l3beqfqx1OX51ez6W9/lQUX1X5vOBv3v4u6cinmtLllTIKakyq7ArfcrJy8tLjB07VrpfUFAg6tev/8wLinv16qWxrGPHjrq/oFgIIa5fFyI+vvDfku6Xt01l9s0aq1cbXY/PGlljdRqfNcqjxgpSYy4oBgrfCh4SEoIlS5bAy8sLc+bMwYYNG/Dnn3/CxsYGwcHBqF+/PqKjowEUvhXc29sbM2fOhJ+fH9atW4cZM2bg1KlTaNWq1XPHK8sFSURERFQ9lOX1W7+KaipVQEAAbt++jSlTpiAtLQ3u7u7YtWuXdNHwtWvXoHziPF+nTp2wdu1afPrpp/jkk0/QtGlTbN26VatgQ0RERPKn8yM3VY1HboiIiGqeGvNWcCIiIqKKxnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLKi869fqGpFH8iclZWl40qIiIhIW0Wv29p8scJLF24ePHgAAHBwcNBxJURERFRWDx48gLm5+TPbvHTfLaVWq3Hr1i3Url0bCoWi3P1kZWXBwcEB169f53dUVTLOddXhXFctznfV4VxXncqaayEEHjx4AHt7e40v1C7JS3fkRqlUokGDBhXWn5mZGX9QqgjnuupwrqsW57vqcK6rTmXM9fOO2BThBcVEREQkKww3REREJCsMN+WkUqkQFRUFlUql61Jkj3NddTjXVYvzXXU411WnOsz1S3dBMREREckbj9wQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDclNPChQvh5OQEQ0NDtG/fHseOHdN1STVedHQ02rVrh9q1a6NevXrw9/dHcnKyRpt//vkHY8aMQd26dWFqaor+/fsjPT1dRxXLw8yZM6FQKDBhwgRpGee5Yt28eRODBw9G3bp1YWRkBDc3N5w4cUJaL4TAlClTYGdnByMjI/j4+ODChQs6rLhmKigowGeffYZGjRrByMgIzs7O+PzzzzW+i4hzXT6//vorevfuDXt7eygUCmzdulVjvTbzevfuXQQFBcHMzAwWFhYIDw9HdnZ25RQsqMzWrVsnDAwMxMqVK8Uff/whhg8fLiwsLER6erquS6vRfH19RUxMjDh37pxITEwUPXv2FA0bNhTZ2dlSm/fee084ODiIffv2iRMnTogOHTqITp066bDqmu3YsWPCyclJtG7dWowfP15aznmuOHfv3hWOjo4iNDRUHD16VFy+fFnExcWJixcvSm1mzpwpzM3NxdatW8WZM2fE22+/LRo1aiRycnJ0WHnN88UXX4i6deuK7du3i5SUFLFx40Zhamoq5s6dK7XhXJfPzz//LCIjI8XmzZsFALFlyxaN9drMa48ePUSbNm3EkSNHxMGDB0WTJk1EYGBgpdTLcFMOXl5eYsyYMdL9goICYW9vL6Kjo3VYlfxkZGQIAOKXX34RQghx//59UatWLbFx40apTVJSkgAgEhISdFVmjfXgwQPRtGlTsWfPHuHt7S2FG85zxZo0aZJ49dVXS12vVquFra2tmDVrlrTs/v37QqVSiR9++KEqSpQNPz8/MXToUI1l/fr1E0FBQUIIznVFeTrcaDOv58+fFwDE8ePHpTY7d+4UCoVC3Lx5s8Jr5GmpMsrLy8PJkyfh4+MjLVMqlfDx8UFCQoIOK5OfzMxMAECdOnUAACdPnsTjx4815t7FxQUNGzbk3JfDmDFj4OfnpzGfAOe5om3btg2enp545513UK9ePbRt2xbLli2T1qekpCAtLU1jvs3NzdG+fXvOdxl16tQJ+/btw19//QUAOHPmDH777Te89dZbADjXlUWbeU1ISICFhQU8PT2lNj4+PlAqlTh69GiF1/TSfXHmi7pz5w4KCgpgY2OjsdzGxgZ//vmnjqqSH7VajQkTJqBz585o1aoVACAtLQ0GBgawsLDQaGtjY4O0tDQdVFlzrVu3DqdOncLx48eLreM8V6zLly9j0aJFiIiIwCeffILjx4/j/fffh4GBAUJCQqQ5Lel3Cue7bD7++GNkZWXBxcUFenp6KCgowBdffIGgoCAA4FxXEm3mNS0tDfXq1dNYr6+vjzp16lTK3DPcULU0ZswYnDt3Dr/99puuS5Gd69evY/z48dizZw8MDQ11XY7sqdVqeHp6YsaMGQCAtm3b4ty5c1i8eDFCQkJ0XJ28bNiwAd9//z3Wrl2Lli1bIjExERMmTIC9vT3n+iXD01JlZGVlBT09vWLvHElPT4etra2OqpKXsWPHYvv27YiPj0eDBg2k5ba2tsjLy8P9+/c12nPuy+bkyZPIyMjAK6+8An19fejr6+OXX37BvHnzoK+vDxsbG85zBbKzs4Orq6vGshYtWuDatWsAIM0pf6e8uH/961/4+OOPMWjQILi5uWHIkCGYOHEioqOjAXCuK4s282pra4uMjAyN9fn5+bh7926lzD3DTRkZGBjAw8MD+/btk5ap1Wrs27cPHTt21GFlNZ8QAmPHjsWWLVuwf/9+NGrUSGO9h4cHatWqpTH3ycnJuHbtGue+DLp3746zZ88iMTFRunl6eiIoKEj6P+e54nTu3LnYRxr89ddfcHR0BAA0atQItra2GvOdlZWFo0ePcr7L6NGjR1AqNV/W9PT0oFarAXCuK4s289qxY0fcv38fJ0+elNrs378farUa7du3r/iiKvwS5ZfAunXrhEqlErGxseL8+fNixIgRwsLCQqSlpem6tBpt1KhRwtzcXBw4cECkpqZKt0ePHklt3nvvPdGwYUOxf/9+ceLECdGxY0fRsWNHHVYtD0++W0oIznNFOnbsmNDX1xdffPGFuHDhgvj++++FsbGxWLNmjdRm5syZwsLCQvz000/i999/F3369OHbk8shJCRE1K9fX3or+ObNm4WVlZX46KOPpDac6/J58OCBOH36tDh9+rQAIGbPni1Onz4trl69KoTQbl579Ogh2rZtK44ePSp+++030bRpU74VvLqZP3++aNiwoTAwMBBeXl7iyJEjui6pxgNQ4i0mJkZqk5OTI0aPHi0sLS2FsbGx6Nu3r0hNTdVd0TLxdLjhPFes//73v6JVq1ZCpVIJFxcXsXTpUo31arVafPbZZ8LGxkaoVCrRvXt3kZycrKNqa66srCwxfvx40bBhQ2FoaCgaN24sIiMjRW5urtSGc10+8fHxJf5+DgkJEUJoN69///23CAwMFKampsLMzEyEhYWJBw8eVEq9CiGe+OhGIiIiohqO19wQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcENFLSaFQYOvWrboug4gqAcMNEVW50NBQKBSKYrcePXroujQikgF9XRdARC+nHj16ICYmRmOZSqXSUTVEJCc8ckNEOqFSqWBra6txs7S0BFB4ymjRokV46623YGRkhMaNG+PHH3/U2P7s2bN4/fXXYWRkhLp162LEiBHIzs7WaLNy5Uq0bNkSKpUKdnZ2GDt2rMb6O3fuoG/fvjA2NkbTpk2xbds2ad29e/cQFBQEa2trGBkZoWnTpsXCGBFVTww3RFQtffbZZ+jfvz/OnDmDoKAgDBo0CElJSQCAhw8fwtfXF5aWljh+/Dg2btyIvXv3aoSXRYsWYcyYMRgxYgTOnj2Lbdu2oUmTJhpjTJs2DQMHDsTvv/+Onj17IigoCHfv3pXGP3/+PHbu3ImkpCQsWrQIVlZWVTcBRFR+lfJ1nEREzxASEiL09PSEiYmJxu2LL74QQhR+Q/x7772nsU379u3FqFGjhBBCLF26VFhaWors7Gxp/Y4dO4RSqRRpaWlCCCHs7e1FZGRkqTUAEJ9++ql0Pzs7WwAQO3fuFEII0bt3bxEWFlYxO0xEVYrX3BCRTnTr1g2LFi3SWFanTh3p/x07dtRY17FjRyQmJgIAkpKS0KZNG5iYmEjrO3fuDLVajeTkZCgUCty6dQvdu3d/Zg2tW7eW/m9iYgIzMzNkZGQAAEaNGoX+/fvj1KlTePPNN+Hv749OnTqVa1+JqGox3BCRTpiYmBQ7TVRRjIyMtGpXq1YtjfsKhQJqtRoA8NZbb+Hq1av4+eefsWfPHnTv3h1jxozBV199VeH1ElHF4jU3RFQtHTlypNj9Fi1aAABatGiBM2fO4OHDh9L6Q4cOQalUonnz5qhduzacnJywb9++F6rB2toaISEhWLNmDebMmYOlS5e+UH9EVDV45IaIdCI3NxdpaWkay/T19aWLdjdu3AhPT0+8+uqr+P7773Hs2DGsWLECABAUFISoqCiEhIRg6tSpuH37NsaNG4chQ4bAxsYGADB16lS89957qFevHt566y08ePAAhw4dwrhx47Sqb8qUKfDw8EDLli2Rm5uL7du3S+GKiKo3hhsi0oldu3bBzs5OY1nz5s3x559/Aih8J9O6deswevRo2NnZ4YcffoCrqysAwNjYGHFxcRg/fjzatWsHY2Nj9O/fH7Nnz5b6CgkJwT///INvvvkGH374IaysrDBgwACt6zMwMMDkyZNx5coVGBkZoUuXLli3bl0F7DkRVTaFEELouggioicpFAps2bIF/v7+ui6FiGogXnNDREREssJwQ0RERLLCa26IqNrh2XIiehE8ckNERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLyf4cWCPTjxXITAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_small_model.history[\"loss\"]\n",
    "epochs = range(1, 101)\n",
    "acc = history_small_model.history[\"accuracy\"]\n",
    "\n",
    "plt.plot(epochs, loss, \"r.\",label=\"Loss\")\n",
    "plt.plot(epochs,acc, \"b\",label=\"Accuracy\")\n",
    "plt.plot(epochs, history_small_model.history[\"val_loss\"], \"r--\",label=\"Validation Loss\")\n",
    "plt.plot(epochs, history_small_model.history[\"val_accuracy\"], \"b.\",label=\"Validation Accuracy\")\n",
    "plt.title(\"Effect of insufficient model capacity on Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
